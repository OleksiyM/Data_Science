{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NM4HKlMi8kH",
    "tags": []
   },
   "source": [
    "# Задача. Зробити модель, яка автоматично буде знаходити негативні коментарі.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/tanulsingh077/deep-learning-for-nlp-zero-to-transformers-bert/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbbmsfowuuYv",
    "tags": []
   },
   "source": [
    "## Інпут даних та огляд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "kVYh8Ke4vNMj",
    "outputId": "49a97eb5-d35e-4cc3-8ca7-5d980b546206",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Зробимо окрему папку для наших даних\n",
    "import os\n",
    "data_path = 'C:/Users/Serhii/Downloads/Lec_24/data'\n",
    "#os.makedirs(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Yq4zDAI4xg7d",
    "outputId": "b1e50153-9e3c-47b5-e62a-e48a7d62eea2"
   },
   "outputs": [],
   "source": [
    "# Завантажимо всі наші дані\n",
    "import pandas as pd\n",
    "\n",
    "train_path = f'{data_path}/jigsaw-toxic-comment-train.csv'\n",
    "val_path = f'{data_path}/validation.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "id": "ZZ0mbFESzSYz",
    "outputId": "10dc4545-eb59-4976-bfc8-3cefc1f440db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 223549 entries, 0 to 223548\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   id             223549 non-null  object\n",
      " 1   comment_text   223549 non-null  object\n",
      " 2   toxic          223549 non-null  int64 \n",
      " 3   severe_toxic   223549 non-null  int64 \n",
      " 4   obscene        223549 non-null  int64 \n",
      " 5   threat         223549 non-null  int64 \n",
      " 6   insult         223549 non-null  int64 \n",
      " 7   identity_hate  223549 non-null  int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 13.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>223549.000000</td>\n",
       "      <td>223549.000000</td>\n",
       "      <td>223549.000000</td>\n",
       "      <td>223549.000000</td>\n",
       "      <td>223549.000000</td>\n",
       "      <td>223549.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095657</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>0.054306</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.050566</td>\n",
       "      <td>0.009470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294121</td>\n",
       "      <td>0.093272</td>\n",
       "      <td>0.226621</td>\n",
       "      <td>0.055431</td>\n",
       "      <td>0.219110</td>\n",
       "      <td>0.096852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  223549.000000  223549.000000  223549.000000  223549.000000   \n",
       "mean        0.095657       0.008777       0.054306       0.003082   \n",
       "std         0.294121       0.093272       0.226621       0.055431   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  223549.000000  223549.000000  \n",
       "mean        0.050566       0.009470  \n",
       "std         0.219110       0.096852  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train_df.info())\n",
    "print('-'*100)\n",
    "display(train_df.describe())\n",
    "print('-'*100)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LbuPWwZZ1Smb",
    "outputId": "a625ca78-7138-4510-a0bb-fd67e4ed9dc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['toxic'] == 1].iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "cJ2H0Ggk1FiN",
    "outputId": "e9c3a449-bef7-4716-92ba-cff956384c6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.comment_text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "O5K9aftpzb8G",
    "outputId": "05a347a7-e026-4833-9313-48ef1953c34d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            8000 non-null   int64 \n",
      " 1   comment_text  8000 non-null   object\n",
      " 2   lang          8000 non-null   object\n",
      " 3   toxic         8000 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 250.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8000.00000</td>\n",
       "      <td>8000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3999.50000</td>\n",
       "      <td>0.153750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2309.54541</td>\n",
       "      <td>0.360731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1999.75000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3999.50000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5999.25000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7999.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id        toxic\n",
       "count  8000.00000  8000.000000\n",
       "mean   3999.50000     0.153750\n",
       "std    2309.54541     0.360731\n",
       "min       0.00000     0.000000\n",
       "25%    1999.75000     0.000000\n",
       "50%    3999.50000     0.000000\n",
       "75%    5999.25000     0.000000\n",
       "max    7999.00000     1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Este usuario ni siquiera llega al rango de    ...</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Il testo di questa voce pare esser scopiazzato...</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vale. Sólo expongo mi pasado. Todo tiempo pasa...</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bu maddenin alt başlığı olarak  uluslararası i...</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Belçika nın şehirlerinin yanında ilçe ve belde...</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       comment_text lang  toxic\n",
       "0   0  Este usuario ni siquiera llega al rango de    ...   es      0\n",
       "1   1  Il testo di questa voce pare esser scopiazzato...   it      0\n",
       "2   2  Vale. Sólo expongo mi pasado. Todo tiempo pasa...   es      1\n",
       "3   3  Bu maddenin alt başlığı olarak  uluslararası i...   tr      0\n",
       "4   4  Belçika nın şehirlerinin yanında ilçe ve belde...   tr      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(val_df.info())\n",
    "display(val_df.describe())\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def roc_auc(predictions,target):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mmli9ebfuxrc",
    "tags": []
   },
   "source": [
    "## Процесінг даних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yAkwvpMIzj-b",
    "outputId": "f9aae676-af43-4d8f-9a5e-639f8eb33d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_words is 1403\n"
     ]
    }
   ],
   "source": [
    "train_df.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True) # Видаляємо непотрібні колонки\n",
    "\n",
    "sample_part = 12000\n",
    "train_df = train_df.loc[:sample_part,:] # Візьмемо частину даних Щоб зробити тренування швидше\n",
    "\n",
    "max_words = train_df['comment_text'].apply(lambda x:len(str(x).split())).max() # Максимальна кількість слів презентована у коментарі\n",
    "print(f'max_words is {max_words}')\n",
    "\n",
    "# Розбиваємо на x|y частини для комфортного використання.\n",
    "X_train = train_df.comment_text\n",
    "y_train = train_df.toxic\n",
    "\n",
    "X_val = val_df.comment_text\n",
    "y_val = val_df.toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "23v-EKSwEikI"
   },
   "outputs": [],
   "source": [
    "# Токенізуємо слова\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.preprocessing import text\n",
    "\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = max_words + 100\n",
    "\n",
    "# translation\n",
    "# regex\n",
    "\n",
    "token.fit_on_texts(list(X_train))\n",
    "xtrain_seq = token.texts_to_sequences(X_train)\n",
    "xvalid_seq = token.texts_to_sequences(X_val)\n",
    "\n",
    "# Додаємо нулі до пропусків (zero padding)\n",
    "xtrain_pad = utils.pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad = utils.pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "# Отримуємо словник слів\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9soUjD60H5UN",
    "outputId": "f32c0a1b-8e14-432d-8cd5-93f6b188963d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оригінальний коментар:\n",
      " Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "--------------------------------------------------\n",
      "Послідовність:\n",
      " [700, 73, 1, 136, 118, 174, 28, 561, 4328, 11057, 1181, 82, 340, 52, 2422, 16020, 50, 6350, 15, 62, 4685, 147, 5, 4025, 34, 120, 1258, 8709, 2725, 3, 51, 64, 267, 1, 385, 33, 1, 39, 27, 135, 70, 4026, 88, 3315, 3745, 2726, 1054]\n",
      "--------------------------------------------------\n",
      "Padding:\n",
      " [   0    0    0 ... 3745 2726 1054]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Оригінальний коментар:\\n', X_train[0])\n",
    "print('-'*50)\n",
    "print('Послідовність:\\n', xtrain_seq[0])\n",
    "print('-'*50)\n",
    "print('Padding:\\n', xtrain_pad[0])\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXJWok1NJPgJ",
    "outputId": "34af53c9-9bc8-45c4-e51b-28764c315015",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Словник слів:\n",
      " [('the', 1), ('to', 2), ('and', 3), ('of', 4), ('i', 5)]\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "print('Словник слів:\\n', list(islice(word_index.items(), 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3V1Ez2au6xU",
    "tags": []
   },
   "source": [
    "## Моделювання"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9C9gtTuE76T",
    "outputId": "053981d3-b519-4a10-afce-c76a1549d246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1503, 300)         13049100  \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 100)               40100     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089,301\n",
      "Trainable params: 13,089,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "model_v1 = Sequential()\n",
    "model_v1.add(Embedding(len(word_index) + 1,\n",
    "                  300,\n",
    "                  input_length=max_len))\n",
    "model_v1.add(SimpleRNN(100))\n",
    "model_v1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_v1.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_v1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "LG3jRQB8Fuhf",
    "outputId": "a31c893e-bb44-4829-f04b-768d277cd303",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "47/47 [==============================] - 89s 2s/step - loss: 0.3299 - accuracy: 0.8977 - val_loss: 0.4305 - val_accuracy: 0.8462\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 89s 2s/step - loss: 0.2329 - accuracy: 0.9169 - val_loss: 0.4943 - val_accuracy: 0.8469\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 90s 2s/step - loss: 0.0763 - accuracy: 0.9751 - val_loss: 0.5606 - val_accuracy: 0.8422\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 90s 2s/step - loss: 0.0126 - accuracy: 0.9979 - val_loss: 0.7081 - val_accuracy: 0.8447\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 91s 2s/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 0.6559 - val_accuracy: 0.8077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2853b5b3f10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v1.fit(xtrain_pad, y_train,\n",
    "          epochs=5,\n",
    "          batch_size=256,\n",
    "          validation_data = (xvalid_pad, y_val),\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMpponjOu-Q8",
    "tags": []
   },
   "source": [
    "## Тестування та збереження"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ljokjAJ3iGmT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 73s 290ms/step\n",
      "Auc: 0.54%\n"
     ]
    }
   ],
   "source": [
    "scores = model_v1.predict(xvalid_pad)\n",
    "print(\"Auc: %.2f%%\" % (roc_auc(scores, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5qFFmNhZiGoy"
   },
   "outputs": [],
   "source": [
    "scores_model = []\n",
    "scores_model.append({'Model': 'SimpleRNN','AUC_Score': roc_auc(scores, y_val)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Інші варіації"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "IsL2GgKLNMF0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196018it [02:41, 13571.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196017 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(f'{data_path}/glove.840B.300d.txt','r',encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray([float(val) for val in values[1:]])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6FZGbBNvNMIS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 43496/43496 [00:00<00:00, 374235.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# створимо матрицю вбудовування для слів, які є в наборі даних\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "9uEwGdG6NMKe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 1503, 300)         13049100  \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 100)               40100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,089,301\n",
      "Trainable params: 40,201\n",
      "Non-trainable params: 13,049,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "model_v2 = Sequential()\n",
    "model_v2.add(Embedding(len(word_index) + 1,\n",
    "                    300,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_len,\n",
    "                    trainable=False\n",
    "                    ))\n",
    "model_v2.add(SimpleRNN(100))\n",
    "model_v2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_v2.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_v2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "KyqaFaAbNMNE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "47/47 [==============================] - 83s 2s/step - loss: 0.2619 - accuracy: 0.9112 - val_loss: 0.5049 - val_accuracy: 0.8405\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 79s 2s/step - loss: 0.1590 - accuracy: 0.9442 - val_loss: 0.4788 - val_accuracy: 0.8257\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 79s 2s/step - loss: 0.1690 - accuracy: 0.9469 - val_loss: 0.7608 - val_accuracy: 0.6344\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 76s 2s/step - loss: 0.2221 - accuracy: 0.9249 - val_loss: 0.5221 - val_accuracy: 0.8242\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 76s 2s/step - loss: 0.2199 - accuracy: 0.9235 - val_loss: 0.4919 - val_accuracy: 0.8246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28823d1ed10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v2.fit(xtrain_pad, y_train,\n",
    "          epochs=5,\n",
    "          batch_size=256,\n",
    "          validation_data = (xvalid_pad, y_val),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "U0ZY-BMZNMPW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 71s 284ms/step\n",
      "Auc: 0.56%\n"
     ]
    }
   ],
   "source": [
    "scores = model_v2.predict(xvalid_pad)\n",
    "print(\"Auc: %.2f%%\" % (roc_auc(scores, y_val)))\n",
    "scores_model.append({'Model': 'Embeding','AUC_Score': roc_auc(scores, y_val)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 1503, 300)         13049100  \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 50)                70200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,119,351\n",
      "Trainable params: 70,251\n",
      "Non-trainable params: 13,049,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model_v3 = Sequential()\n",
    "model_v3.add(Embedding(len(word_index) + 1,\n",
    "                    300,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_len,\n",
    "                    trainable=False\n",
    "                    ))\n",
    "model_v3.add(LSTM(50))\n",
    "model_v3.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_v3.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_v3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "47/47 [==============================] - 12s 223ms/step - loss: 0.3012 - accuracy: 0.8993 - val_loss: 0.4688 - val_accuracy: 0.8366\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 10s 214ms/step - loss: 0.1727 - accuracy: 0.9373 - val_loss: 0.4642 - val_accuracy: 0.7850\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 10s 216ms/step - loss: 0.1286 - accuracy: 0.9523 - val_loss: 0.5804 - val_accuracy: 0.6950\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 10s 215ms/step - loss: 0.1192 - accuracy: 0.9563 - val_loss: 0.5733 - val_accuracy: 0.7279\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 10s 216ms/step - loss: 0.1082 - accuracy: 0.9612 - val_loss: 0.5777 - val_accuracy: 0.7779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2882c32e4d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v3.fit(xtrain_pad, y_train,\n",
    "          epochs=5,\n",
    "          batch_size=256,\n",
    "          validation_data = (xvalid_pad, y_val),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 7s 28ms/step\n",
      "Auc: 0.61%\n"
     ]
    }
   ],
   "source": [
    "scores = model_v3.predict(xvalid_pad)\n",
    "print(\"Auc: %.2f%%\" % (roc_auc(scores, y_val)))\n",
    "scores_model.append({'Model': 'LSTM','AUC_Score': roc_auc(scores, y_val)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 1503, 300)         13049100  \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 50)                52800     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,101,951\n",
      "Trainable params: 52,851\n",
      "Non-trainable params: 13,049,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "\n",
    "model_v4 = Sequential()\n",
    "model_v4.add(Embedding(len(word_index) + 1,\n",
    "                    300,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_len,\n",
    "                    trainable=False\n",
    "                    ))\n",
    "model_v4.add(GRU(50))\n",
    "model_v4.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_v4.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_v4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "94/94 [==============================] - 13s 120ms/step - loss: 0.2552 - accuracy: 0.9133 - val_loss: 0.5626 - val_accuracy: 0.8443\n",
      "Epoch 2/5\n",
      "94/94 [==============================] - 11s 116ms/step - loss: 0.1277 - accuracy: 0.9516 - val_loss: 0.4801 - val_accuracy: 0.8075\n",
      "Epoch 3/5\n",
      "94/94 [==============================] - 11s 120ms/step - loss: 0.1090 - accuracy: 0.9594 - val_loss: 0.4701 - val_accuracy: 0.8066\n",
      "Epoch 4/5\n",
      "94/94 [==============================] - 11s 122ms/step - loss: 0.0966 - accuracy: 0.9646 - val_loss: 0.5109 - val_accuracy: 0.7885\n",
      "Epoch 5/5\n",
      "94/94 [==============================] - 11s 117ms/step - loss: 0.0876 - accuracy: 0.9674 - val_loss: 0.5504 - val_accuracy: 0.7574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2852a9673d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v4.fit(xtrain_pad, y_train,\n",
    "          epochs=5,\n",
    "          batch_size=128,\n",
    "          validation_data = (xvalid_pad, y_val),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 7s 26ms/step\n",
      "Auc: 0.64%\n"
     ]
    }
   ],
   "source": [
    "scores = model_v4.predict(xvalid_pad)\n",
    "print(\"Auc: %.2f%%\" % (roc_auc(scores, y_val)))\n",
    "scores_model.append({'Model': 'GRU','AUC_Score': roc_auc(scores, y_val)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model': 'SimpleRNN', 'AUC_Score': 0.5356438015635696},\n",
       " {'Model': 'Embeding', 'AUC_Score': 0.5593912046210566},\n",
       " {'Model': 'LSTM', 'AUC_Score': 0.6147155071993851},\n",
       " {'Model': 'GRU', 'AUC_Score': 0.6398685616841397}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bi-Directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 1503, 300)         13049100  \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              241200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,290,501\n",
      "Trainable params: 241,401\n",
      "Non-trainable params: 13,049,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense\n",
    "\n",
    "model_v5 = Sequential()\n",
    "model_v5.add(Embedding(len(word_index) + 1,\n",
    "                    300,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_len,\n",
    "                    trainable=False\n",
    "                    ))\n",
    "model_v5.add(Bidirectional(GRU(50)))\n",
    "model_v5.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_v5.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_v5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "94/94 [==============================] - 37s 367ms/step - loss: 0.2315 - accuracy: 0.9163 - val_loss: 0.4469 - val_accuracy: 0.8300\n",
      "Epoch 2/5\n",
      "94/94 [==============================] - 33s 356ms/step - loss: 0.1303 - accuracy: 0.9546 - val_loss: 0.5508 - val_accuracy: 0.8432\n",
      "Epoch 3/5\n",
      "94/94 [==============================] - 34s 359ms/step - loss: 0.1045 - accuracy: 0.9611 - val_loss: 0.5535 - val_accuracy: 0.8395\n",
      "Epoch 4/5\n",
      "94/94 [==============================] - 33s 354ms/step - loss: 0.0946 - accuracy: 0.9637 - val_loss: 0.5147 - val_accuracy: 0.8254\n",
      "Epoch 5/5\n",
      "94/94 [==============================] - 32s 340ms/step - loss: 0.0836 - accuracy: 0.9680 - val_loss: 0.6559 - val_accuracy: 0.8443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x288349923e0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v5.fit(xtrain_pad, y_train,\n",
    "          epochs=5,\n",
    "          batch_size=128,\n",
    "          validation_data = (xvalid_pad, y_val),\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 17s 66ms/step\n",
      "Auc: 0.62%\n"
     ]
    }
   ],
   "source": [
    "scores = model_v5.predict(xvalid_pad)\n",
    "print(\"Auc: %.2f%%\" % (roc_auc(scores, y_val)))\n",
    "scores_model.append({'Model': 'BI-DIR','AUC_Score': roc_auc(scores, y_val)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Model': 'SimpleRNN', 'AUC_Score': 0.5356438015635696},\n",
       " {'Model': 'Embeding', 'AUC_Score': 0.5593912046210566},\n",
       " {'Model': 'LSTM', 'AUC_Score': 0.6147155071993851},\n",
       " {'Model': 'GRU', 'AUC_Score': 0.6398685616841397},\n",
       " {'Model': 'BI-DIR', 'AUC_Score': 0.623741758835609}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_3_layer_call_fn, gru_cell_3_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/Serhii/Downloads/Lec_24//model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/Serhii/Downloads/Lec_24//model\\assets\n"
     ]
    }
   ],
   "source": [
    "path_to_save = 'C:/Users/Serhii/Downloads/Lec_24/'\n",
    "model_v5.save(f'{path_to_save}/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# download model\n",
    "model_loaded = load_model(f'{path_to_save}/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_len = max_words + 100\n",
    "# download X\n",
    "test_path = f'{data_path}/test.csv'\n",
    "test_df = pd.read_csv(test_path)\n",
    "X_test = test_df.content\n",
    "X_test_seq = token.texts_to_sequences(X_test)\n",
    "X_test_pad = utils.pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# download y\n",
    "test_labels = f'{data_path}/test_labels.csv'\n",
    "test_labels = pd.read_csv(test_labels)\n",
    "y_test = test_labels.toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Doctor Who adlı viki başlığına 12. doctor olar...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Вполне возможно, но я пока не вижу необходимо...</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Quindi tu sei uno di quelli   conservativi  , ...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu ...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63807</th>\n",
       "      <td>63807</td>\n",
       "      <td>No, non risponderò, come preannunciato. Prefer...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63808</th>\n",
       "      <td>63808</td>\n",
       "      <td>Ciao, I tecnici della Wikimedia Foundation sta...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63809</th>\n",
       "      <td>63809</td>\n",
       "      <td>innnazitutto ti ringrazio per i ringraziamenti...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63810</th>\n",
       "      <td>63810</td>\n",
       "      <td>Kaç olumlu oy gerekiyor? Şu an 7 oldu.  Hayır...</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63811</th>\n",
       "      <td>63811</td>\n",
       "      <td>Te pido disculpas. La verdad es que no me per...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63812 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                            content lang\n",
       "0          0  Doctor Who adlı viki başlığına 12. doctor olar...   tr\n",
       "1          1   Вполне возможно, но я пока не вижу необходимо...   ru\n",
       "2          2  Quindi tu sei uno di quelli   conservativi  , ...   it\n",
       "3          3  Malesef gerçekleştirilmedi ancak şöyle bir şey...   tr\n",
       "4          4  :Resim:Seldabagcan.jpg resminde kaynak sorunu ...   tr\n",
       "...      ...                                                ...  ...\n",
       "63807  63807  No, non risponderò, come preannunciato. Prefer...   it\n",
       "63808  63808  Ciao, I tecnici della Wikimedia Foundation sta...   it\n",
       "63809  63809  innnazitutto ti ringrazio per i ringraziamenti...   it\n",
       "63810  63810   Kaç olumlu oy gerekiyor? Şu an 7 oldu.  Hayır...   tr\n",
       "63811  63811   Te pido disculpas. La verdad es que no me per...   es\n",
       "\n",
       "[63812 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995/1995 [==============================] - 139s 69ms/step - loss: 1.0438 - accuracy: 0.7741\n",
      "loss = 1.0438292026519775; accuracy = 0.7741490602493286\n"
     ]
    }
   ],
   "source": [
    "# Final check\n",
    "test_loss, test_acc = model_loaded.evaluate(X_test_pad, y_test)\n",
    "print(f'loss = {test_loss}; accuracy = {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995/1995 [==============================] - 131s 65ms/step\n",
      "AUC_Score: 0.5707888371291219\n"
     ]
    }
   ],
   "source": [
    "test_labels['toxic_pred'] = model_loaded.predict(X_test_pad, verbose=1) # Write results\n",
    "print('AUC_Score:', roc_auc(test_labels['toxic_pred'] , y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.to_csv('results.csv', index=False) # save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Як використати BERT?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/text/tutorials/classify_text_with_bert#loading_the_bert_model_and_training"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py310_tf210_gpu",
   "language": "python",
   "name": "py310_tf210_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
