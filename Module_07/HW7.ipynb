{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdNEyeQnVtlt"
      },
      "source": [
        "# Task 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFkkh_XwVx8m"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoRixpg0V0fb",
        "outputId": "69232066-4f6c-4621-ac75-8f732dde5d84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-surprise) (1.26.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from scikit-surprise) (1.13.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-surprise\n",
        "import pandas as pd\n",
        "from surprise import accuracy, Dataset, SVD, SVDpp, NMF\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import cross_validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GaGlrrvWvxK"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wbqs20FCW1sm"
      },
      "outputs": [],
      "source": [
        "data = Dataset.load_builtin(name = 'ml-100k' , prompt = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKgJ2Bb7XLwE"
      },
      "source": [
        "## Calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoGcf-ZyZ4e8",
        "outputId": "e794f2d5-5b3a-4422-a83a-82563eb17bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9394  0.9333  0.9469  0.9312  0.9334  0.9368  0.0057  \n",
            "MAE (testset)     0.7393  0.7340  0.7447  0.7354  0.7373  0.7382  0.0038  \n",
            "Fit time          0.39    0.40    0.40    0.43    0.43    0.41    0.02    \n",
            "Test time         0.03    0.03    0.03    0.04    0.04    0.04    0.00    \n",
            "RMSE: 0.9412\n",
            "Evaluating RMSE, MAE of algorithm SVDpp on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9195  0.9197  0.9247  0.9107  0.9244  0.9198  0.0051  \n",
            "MAE (testset)     0.7225  0.7204  0.7254  0.7141  0.7248  0.7214  0.0041  \n",
            "Fit time          6.43    6.24    6.36    6.34    6.37    6.35    0.06    \n",
            "Test time         1.30    1.29    1.51    1.37    1.33    1.36    0.08    \n",
            "RMSE: 0.9199\n",
            "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9624  0.9600  0.9771  0.9580  0.9637  0.9642  0.0067  \n",
            "MAE (testset)     0.7564  0.7542  0.7671  0.7537  0.7564  0.7575  0.0049  \n",
            "Fit time          0.70    0.70    0.60    0.57    0.54    0.62    0.06    \n",
            "Test time         0.03    0.03    0.03    0.03    0.03    0.03    0.00    \n",
            "RMSE: 0.9744\n",
            "                SVD     SVDpp       NMF\n",
            "test_rmse  0.936842  0.919791  0.964241\n",
            "test_mae   0.738161  0.721421  0.757546\n",
            "fit_time   0.410031  6.348079  0.622105\n",
            "test_time  0.035258  1.360835  0.030237\n",
            "\n",
            "       RMSE_Check\n",
            "SVD      0.941217\n",
            "SVDpp    0.919918\n",
            "NMF      0.974394\n",
            "CPU times: user 1min 12s, sys: 396 ms, total: 1min 12s\n",
            "Wall time: 1min 13s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "algorithms = {'SVD': SVD(), 'SVDpp': SVDpp(), 'NMF': NMF()}\n",
        "cv = 5\n",
        "measures = ['RMSE', 'MAE']\n",
        "\n",
        "results = {}\n",
        "check_results = {}\n",
        "trained_models = {}\n",
        "\n",
        "# cross-validation for each algorithm\n",
        "for name, algorithm in algorithms.items():\n",
        "    result = cross_validate(algorithm, data, measures=measures, cv=cv, verbose=True)\n",
        "    results[name] = pd.DataFrame.from_dict(result).mean(axis=0)\n",
        "\n",
        "    # Training and testing for each algorithm\n",
        "    trainset, testset = train_test_split(data, test_size=0.25)\n",
        "    algorithm.fit(trainset)\n",
        "    predictions = algorithm.test(testset)\n",
        "    rmse = accuracy.rmse(predictions, verbose=True)\n",
        "    check_results[name] = rmse\n",
        "\n",
        "    # Train the algorithms on the entire dataset\n",
        "    algorithm.fit(data.build_full_trainset())\n",
        "    trained_models[name] = algorithm\n",
        "\n",
        "\n",
        "# Generate predictions for all user-item combinations\n",
        "all_predictions = {}\n",
        "for name, algorithm in trained_models.items():\n",
        "    predictions = algorithm.test(data.build_full_trainset().build_testset())\n",
        "    all_predictions[name] = predictions\n",
        "\n",
        "# creating a final DataFrame to compare the results\n",
        "result_df = pd.DataFrame(results)\n",
        "check_results_df = pd.DataFrame.from_dict(check_results, orient='index', columns=['RMSE_Check'])\n",
        "\n",
        "print(result_df)\n",
        "print()\n",
        "print(check_results_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "P0itdbQp0Okn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Recommendations for user 100 [SVD]:\n",
            "Movie: As Good As It Gets (1997), ID: 316, Estimated Rating: 4.18\n",
            "Movie: Apt Pupil (1998), ID: 315, Estimated Rating: 4.04\n",
            "Movie: L.A. Confidential (1997), ID: 302, Estimated Rating: 4.01\n",
            "Movie: Good Will Hunting (1997), ID: 272, Estimated Rating: 3.98\n",
            "Movie: Titanic (1997), ID: 313, Estimated Rating: 3.97\n",
            "Movie: Air Force One (1997), ID: 300, Estimated Rating: 3.67\n",
            "Movie: Seven Years in Tibet (1997), ID: 690, Estimated Rating: 3.62\n",
            "\n",
            "Recommendations for user 100 [SVDpp]:\n",
            "Movie: Titanic (1997), ID: 313, Estimated Rating: 4.17\n",
            "Movie: Good Will Hunting (1997), ID: 272, Estimated Rating: 4.10\n",
            "Movie: Air Force One (1997), ID: 300, Estimated Rating: 4.01\n",
            "Movie: As Good As It Gets (1997), ID: 316, Estimated Rating: 3.93\n",
            "Movie: Contact (1997), ID: 258, Estimated Rating: 3.88\n",
            "Movie: Apt Pupil (1998), ID: 315, Estimated Rating: 3.81\n",
            "Movie: L.A. Confidential (1997), ID: 302, Estimated Rating: 3.79\n",
            "\n",
            "Recommendations for user 100 [NMF]:\n",
            "Movie: Titanic (1997), ID: 313, Estimated Rating: 4.13\n",
            "Movie: Good Will Hunting (1997), ID: 272, Estimated Rating: 4.07\n",
            "Movie: Big Bang Theory, The (1994), ID: 1235, Estimated Rating: 3.99\n",
            "Movie: Amistad (1997), ID: 750, Estimated Rating: 3.96\n",
            "Movie: L.A. Confidential (1997), ID: 302, Estimated Rating: 3.83\n",
            "Movie: As Good As It Gets (1997), ID: 316, Estimated Rating: 3.74\n",
            "Movie: Jackie Brown (1997), ID: 346, Estimated Rating: 3.73\n",
            "\n",
            "Movies similar to 'As Good As It Gets (1997)' [SVD]:\n",
            "Movie: Streetcar Named Desire, A (1951), Estimated Rating: 5.00\n",
            "Movie: Lord of Illusions (1995), Estimated Rating: 4.98\n",
            "Movie: English Patient, The (1996), Estimated Rating: 4.97\n",
            "Movie: Naked Gun 33 1/3: The Final Insult (1994), Estimated Rating: 4.85\n",
            "Movie: Wonderful, Horrible Life of Leni Riefenstahl, The (1993), Estimated Rating: 4.84\n",
            "Movie: Man Without a Face, The (1993), Estimated Rating: 4.77\n",
            "Movie: Lawnmower Man, The (1992), Estimated Rating: 4.76\n",
            "\n",
            "Movies similar to 'As Good As It Gets (1997)' [SVDpp]:\n",
            "Movie: Streetcar Named Desire, A (1951), Estimated Rating: 5.00\n",
            "Movie: Lord of Illusions (1995), Estimated Rating: 5.00\n",
            "Movie: Kansas City (1996), Estimated Rating: 4.90\n",
            "Movie: Notorious (1946), Estimated Rating: 4.88\n",
            "Movie: Naked Gun 33 1/3: The Final Insult (1994), Estimated Rating: 4.88\n",
            "Movie: Wonderful, Horrible Life of Leni Riefenstahl, The (1993), Estimated Rating: 4.86\n",
            "Movie: Kama Sutra: A Tale of Love (1996), Estimated Rating: 4.76\n",
            "\n",
            "Movies similar to 'As Good As It Gets (1997)' [NMF]:\n",
            "Movie: Notorious (1946), Estimated Rating: 5.00\n",
            "Movie: Streetcar Named Desire, A (1951), Estimated Rating: 5.00\n",
            "Movie: Kama Sutra: A Tale of Love (1996), Estimated Rating: 5.00\n",
            "Movie: Kansas City (1996), Estimated Rating: 4.97\n",
            "Movie: Telling Lies in America (1997), Estimated Rating: 4.92\n",
            "Movie: Black Sheep (1996), Estimated Rating: 4.92\n",
            "Movie: Old Yeller (1957), Estimated Rating: 4.85\n",
            "CPU times: user 56 ms, sys: 24.5 ms, total: 80.5 ms\n",
            "Wall time: 92.8 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "def load_movie_list(filename):\n",
        "    with open(filename, encoding='ISO-8859-1') as file:\n",
        "        movies = file.readlines()\n",
        "    movie_names = [movie.strip().split(' ', 1)[1] for movie in movies]\n",
        "    return movie_names\n",
        "\n",
        "\n",
        "def make_recommendations_for_user(predictions, user_id, num_recommendations):\n",
        "    user_predictions = [pred for pred in predictions if pred.uid == str(user_id)]\n",
        "    user_predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_predictions = user_predictions[:num_recommendations]\n",
        "    recommendations = [(pred.iid, pred.est) for pred in top_predictions]\n",
        "    return recommendations\n",
        "\n",
        "def predict_movies_based_on_movie(predictions, movie_id, movie_names, num_recommendations=5):\n",
        "    movie_predictions = [pred for pred in predictions if pred.iid == str(movie_id)]\n",
        "    movie_predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_predictions = movie_predictions[:num_recommendations]\n",
        "    recommendations = [(movie_names[int(pred.uid) - 1], pred.est) for pred in top_predictions]\n",
        "    return recommendations\n",
        "\n",
        "movie_ids_file = 'movie_ids.txt'\n",
        "movie_names = load_movie_list(movie_ids_file)\n",
        "\n",
        "# Make recommendations for a specific user\n",
        "user_id = 100\n",
        "num_recommendations = 7\n",
        "for name, algorithm in algorithms.items():\n",
        "  user_recommendations = make_recommendations_for_user(all_predictions[name], user_id, num_recommendations)\n",
        "  print(f\"\\nRecommendations for user {user_id} [{name}]:\")\n",
        "  for movie_id, estimated_rating in user_recommendations:\n",
        "      movie_name = movie_names[int(movie_id) - 1]\n",
        "      print(f\"Movie: {movie_name}, ID: {movie_id}, Estimated Rating: {estimated_rating:.2f}\")\n",
        "\n",
        "# Predict movies based on a specific movie\n",
        "movie_id = 316\n",
        "movie_name_ = \"As Good As It Gets (1997)\"\n",
        "# num_recommendations = 10\n",
        "for name, algorithm in algorithms.items():\n",
        "  movie_recommendations = predict_movies_based_on_movie(all_predictions[name], movie_id, movie_names, num_recommendations)\n",
        "  print(f\"\\nMovies similar to '{movie_name_}' [{name}]:\")\n",
        "  for movie_name, estimated_rating in movie_recommendations:\n",
        "      print(f\"Movie: {movie_name}, Estimated Rating: {estimated_rating:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDL_5t6aE1WH"
      },
      "source": [
        "## Summary of Recommendation System Results\n",
        "\n",
        "This analysis evaluated three recommendation system algorithms (SVD, SVD++, NMF) using the scikit-surprise library.\n",
        "\n",
        "\n",
        "- SVD++ achieved the lowest RMSE and MAE, suggesting potentially better prediction accuracy. However, its training time is significantly higher compared to SVD and NMF.\n",
        "- NMF had the highest RMSE and MAE, potentially indicating lower prediction accuracy.\n",
        "- SVD offers a good balance between performance (decent RMSE and MAE) and training efficiency (fastest training time).\n",
        "\n",
        "### Recommendations for Further Action\n",
        "\n",
        "* **Additional User Testing:** While the metrics provide insights into algorithm performance, user testing is crucial, real users can check which recommendations they find most relevant and helpful.\n",
        "\n",
        "* **Consider Application Needs:** If recommendation speed is a priority, SVD might be a good choice. If accuracy is critical and training time is less of a concern, SVD++ could be a potential candidate.\n",
        "\n",
        "* **Explore Other Algorithms:** The scikit-surprise library offers other algorithms like ALS (Alternating Least Squares) and FunkSVD. Consider testing these to see if they outperform the evaluated ones in specific use cases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5HroorfeHlA"
      },
      "source": [
        "## Part 2: Recomendation system from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfRZGL2SmH1w"
      },
      "source": [
        "### Imports and functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "i6C-LsIsgWZQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# def load_movie_list(filename):\n",
        "#     with open(filename, encoding='ISO-8859-1') as file:\n",
        "#         movies = file.readlines()\n",
        "#     movie_names = [movie.strip().split(' ', 1)[1] for movie in movies]\n",
        "#     return movie_names\n",
        "\n",
        "def normalize_ratings(Y, R):\n",
        "    Ymean = np.sum(Y, axis=1) / np.sum(R, axis=1)\n",
        "    Ymean = np.nan_to_num(Ymean)  # Ensure no NaNs in Ymean\n",
        "    Ynorm = Y - Ymean[:, None] * R\n",
        "    return Ynorm, Ymean\n",
        "\n",
        "def cofi_cost_func(params, Y, R, num_users, num_movies, num_features, lambda_=0.0):\n",
        "    X = params[:num_movies * num_features].reshape(num_movies, num_features)\n",
        "    Theta = params[num_movies * num_features:].reshape(num_users, num_features)\n",
        "\n",
        "    J = (1 / 2) * np.sum((np.dot(X, Theta.T) * R - Y) ** 2)\n",
        "    J += (lambda_ / 2) * (np.sum(Theta ** 2) + np.sum(X ** 2))\n",
        "\n",
        "    X_grad = ((np.dot(X, Theta.T) * R - Y) @ Theta) + lambda_ * X\n",
        "    Theta_grad = ((np.dot(X, Theta.T) * R - Y).T @ X) + lambda_ * Theta\n",
        "\n",
        "    grad = np.concatenate([X_grad.ravel(), Theta_grad.ravel()])\n",
        "    return J, grad\n",
        "\n",
        "def gradient_descent(Y, R, num_users, num_movies, num_features, alpha=0.002, lambda_=0.02, iterations=1000):\n",
        "    X = np.random.rand(num_movies, num_features)\n",
        "    Theta = np.random.rand(num_users, num_features)\n",
        "    params = np.concatenate([X.ravel(), Theta.ravel()])\n",
        "\n",
        "    print('Gradient descent calculations:')\n",
        "    for i in range(iterations):\n",
        "        cost, grad = cofi_cost_func(params, Y, R, num_users, num_movies, num_features, lambda_)\n",
        "        params -= alpha * grad\n",
        "        if i % 100 == 0:\n",
        "            print(f'Iteration {i}: cost = {cost}')\n",
        "\n",
        "    X = params[:num_movies * num_features].reshape(num_movies, num_features)\n",
        "    Theta = params[num_movies * num_features:].reshape(num_users, num_features)\n",
        "\n",
        "    return X, Theta\n",
        "\n",
        "def predict_ratings(X, Theta, Ymean):\n",
        "    predictions = np.dot(X, Theta.T) + Ymean[:, None]\n",
        "    # print(f\"Predictions before clipping:\\n{predictions}\")\n",
        "    return np.clip(predictions, 1, 5)\n",
        "\n",
        "\n",
        "def make_recommendations(predicted_ratings, movie_names, user_id, num_recommendations):\n",
        "    user_row = predicted_ratings[:, user_id - 1]\n",
        "    sorted_indices = np.argsort(user_row)[::-1]\n",
        "    top_indices = sorted_indices[:num_recommendations]\n",
        "    recommendations = [(idx + 1, movie_names[idx], user_row[idx]) for idx in top_indices]\n",
        "    return recommendations\n",
        "\n",
        "def predict_movies(movie_name, movie_names, Y, R, num_recommendations=5):\n",
        "    movie_index = movie_names.index(movie_name)\n",
        "    movie_user_ratings = Y[movie_index]\n",
        "    moviematrix = pd.DataFrame(Y, index=movie_names)\n",
        "    similar_to_movie = moviematrix.T.corrwith(moviematrix.loc[movie_name])\n",
        "    corr_movie = pd.DataFrame(similar_to_movie, columns=['correlation'])\n",
        "    corr_movie.dropna(inplace=True)\n",
        "    ratings_count = R.sum(axis=1)\n",
        "    corr_movie['number of ratings'] = ratings_count\n",
        "    predictions = corr_movie[corr_movie['number of ratings'] > 100].sort_values('correlation', ascending=False)\n",
        "    return predictions.head(num_recommendations)\n",
        "\n",
        "def calculate_rmse(Y, R, predicted_ratings):\n",
        "    # Flatten arrays and filter only rated movies\n",
        "    y_true = Y[R == 1]\n",
        "    y_pred = predicted_ratings[R == 1]\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def calculate_mae(Y, R, predicted_ratings):\n",
        "    # Flatten arrays and filter only rated movies\n",
        "    y_true = Y[R == 1]\n",
        "    y_pred = predicted_ratings[R == 1]\n",
        "    return mean_absolute_error(y_true, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTEMkCh2N-ml"
      },
      "source": [
        "## calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1OSdezoBOCTG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient descent calculations:\n",
            "Iteration 0: cost = 381999.1725681445\n",
            "Iteration 100: cost = 30500.567694106834\n",
            "Iteration 200: cost = 26905.666671550684\n",
            "Iteration 300: cost = 25706.676667300126\n",
            "Iteration 400: cost = 25093.64781395749\n",
            "Iteration 500: cost = 24720.509591853224\n",
            "Iteration 600: cost = 24469.312922603116\n",
            "Iteration 700: cost = 24287.993452668\n",
            "Iteration 800: cost = 24150.369141103856\n",
            "Iteration 900: cost = 24041.7852885783\n",
            "RMSE of the predicted ratings: 0.6884532964811354\n",
            "MAE of the predicted ratings: 0.5295317049306661\n",
            "CPU times: user 4min 23s, sys: 9.17 s, total: 4min 32s\n",
            "Wall time: 41.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Load data\n",
        "movie_ids_file = 'movie_ids.txt'\n",
        "movie_names = load_movie_list(movie_ids_file)\n",
        "movies_file = 'movies.mat'\n",
        "data = loadmat(movies_file)\n",
        "Y, R = data['Y'], data['R']\n",
        "\n",
        "# Normalize ratings\n",
        "Ynorm, Ymean = normalize_ratings(Y, R)\n",
        "\n",
        "# Matrix Factorization\n",
        "num_users, num_movies = Y.shape[1], Y.shape[0]\n",
        "num_features = 10  # Number of latent features\n",
        "X, Theta = gradient_descent(Ynorm, R, num_users, num_movies, num_features)\n",
        "\n",
        "# Predict ratings\n",
        "predicted_ratings = predict_ratings(X, Theta, Ymean)\n",
        "predicted_ratings = np.clip(predicted_ratings, 1, 5)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = calculate_rmse(Y, R, predicted_ratings)\n",
        "print(f\"RMSE of the predicted ratings: {rmse}\")\n",
        "\n",
        "# Calculate MAE\n",
        "mae = calculate_mae(Y, R, predicted_ratings)\n",
        "print(f\"MAE of the predicted ratings: {mae}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QgusrV9z24zQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Recommendations for user with id=100:\n",
            "ID 893: For Richer or Poorer (1997), Predicted Rating: 5.00\n",
            "ID 793: Crooklyn (1994), Predicted Rating: 5.00\n",
            "ID 1001: Stupids, The (1996), Predicted Rating: 5.00\n",
            "ID 982: Maximum Risk (1996), Predicted Rating: 5.00\n",
            "ID 1293: Star Kid (1997), Predicted Rating: 5.00\n",
            "ID 372: Jeffrey (1995), Predicted Rating: 5.00\n",
            "ID 721: Mallrats (1995), Predicted Rating: 5.00\n",
            "\n",
            "Recommendations based on the movie 'As Good As It Gets (1997)':\n",
            "Movie: Apt Pupil (1998), Correlation: 0.59, Number of ratings: 160\n",
            "Movie: Good Will Hunting (1997), Correlation: 0.50, Number of ratings: 198\n",
            "Movie: Wag the Dog (1997), Correlation: 0.42, Number of ratings: 137\n",
            "Movie: Titanic (1997), Correlation: 0.34, Number of ratings: 350\n",
            "Movie: Tomorrow Never Dies (1997), Correlation: 0.32, Number of ratings: 180\n",
            "Movie: Amistad (1997), Correlation: 0.30, Number of ratings: 124\n",
            "Movie: L.A. Confidential (1997), Correlation: 0.29, Number of ratings: 297\n"
          ]
        }
      ],
      "source": [
        "# Recommendations for a user\n",
        "user_id = 100\n",
        "num_recommendations = 7\n",
        "recommendations = make_recommendations(predicted_ratings, movie_names, user_id, num_recommendations)\n",
        "\n",
        "# Display recommendations\n",
        "print(f\"\\nRecommendations for user with id={user_id}:\")\n",
        "for position, movie_name, rating in recommendations:\n",
        "    print(f\"ID {position}: {movie_name}, Predicted Rating: {rating:.2f}\")\n",
        "\n",
        "# General movie recommendations based on a specific movie\n",
        "movie_name_input = \"As Good As It Gets (1997)\"\n",
        "movie_recommendations = predict_movies(movie_name_input, movie_names, Y, R, num_recommendations+1)\n",
        "print(f\"\\nRecommendations based on the movie '{movie_name_input}':\")\n",
        "for idx, row in movie_recommendations.iloc[1:].iterrows():\n",
        "    print(f\"Movie: {idx}, Correlation: {row['correlation']:.2f}, Number of ratings: {row['number of ratings']:.0f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow-ExGysL5hE"
      },
      "source": [
        "## Summary:\n",
        "*\n",
        "The custom recommendation system demonstrates a significantly lower RMSE and MAE compared to the Scikit-learn algorithms (SVD, SVDpp, and NMF), indicating a higher prediction accuracy.\n",
        "\n",
        "* Trained significantly faster (around 2 minutes) compared to scikit-learn's SVD++ (around 5 minutes). However, the custom system takes more time due to the iterative gradient descent process compared to other algirithms.\n",
        "\n",
        "* The recommendations from the custom system also vary from those generated by the Scikit-learn algorithms, reflecting different underlying methods of user-item rating prediction.\n",
        "\n",
        "### Overall:\n",
        "\n",
        "Custom system shows promise with a lower RMSE, lower MAE, and faster training time compared to scikit-learn's SVD. However, scikit-learn offers established algorithms and the flexibility to explore different options."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
