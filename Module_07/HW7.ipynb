{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 7"
      ],
      "metadata": {
        "id": "vdNEyeQnVtlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "WFkkh_XwVx8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise\n",
        "import pandas as pd\n",
        "from surprise import accuracy, Dataset, SVD, SVDpp, NMF\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import cross_validate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoRixpg0V0fb",
        "outputId": "35e3a6db-64ca-418c-fad0-c1f1bb2c0ed9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/154.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357257 sha256=981d9d69bdd5c1b99236ca57a6197401fad32ece4ffe281b17f39e00fd754147\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "3GaGlrrvWvxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset.load_builtin(name = 'ml-100k' , prompt = False)"
      ],
      "metadata": {
        "id": "wbqs20FCW1sm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9beb2a7d-cfab-479f-801c-557c19812580"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "ZKgJ2Bb7XLwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "algorithms = {'SVD': SVD(), 'SVDpp': SVDpp(), 'NMF': NMF()}\n",
        "cv = 5\n",
        "measures = ['RMSE', 'MAE']\n",
        "\n",
        "results = {}\n",
        "check_results = {}\n",
        "trained_models = {}\n",
        "\n",
        "# cross-validation for each algorithm\n",
        "for name, algorithm in algorithms.items():\n",
        "    result = cross_validate(algorithm, data, measures=measures, cv=cv, verbose=True)\n",
        "    results[name] = pd.DataFrame.from_dict(result).mean(axis=0)\n",
        "\n",
        "    # Training and testing for each algorithm\n",
        "    trainset, testset = train_test_split(data, test_size=0.25)\n",
        "    algorithm.fit(trainset)\n",
        "    predictions = algorithm.test(testset)\n",
        "    rmse = accuracy.rmse(predictions, verbose=True)\n",
        "    check_results[name] = rmse\n",
        "\n",
        "    # Train the algorithms on the entire dataset\n",
        "    algorithm.fit(data.build_full_trainset())\n",
        "    trained_models[name] = algorithm\n",
        "\n",
        "\n",
        "# Generate predictions for all user-item combinations\n",
        "all_predictions = {}\n",
        "for name, algorithm in trained_models.items():\n",
        "    predictions = algorithm.test(data.build_full_trainset().build_testset())\n",
        "    all_predictions[name] = predictions\n",
        "\n",
        "# creating a final DataFrame to compare the results\n",
        "result_df = pd.DataFrame(results)\n",
        "check_results_df = pd.DataFrame.from_dict(check_results, orient='index', columns=['RMSE_Check'])\n",
        "\n",
        "print(result_df)\n",
        "print()\n",
        "print(check_results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoGcf-ZyZ4e8",
        "outputId": "b7363179-d1b6-488c-e0a4-b91f4dd8d8c1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9332  0.9370  0.9321  0.9411  0.9357  0.9358  0.0032  \n",
            "MAE (testset)     0.7370  0.7419  0.7330  0.7408  0.7382  0.7382  0.0031  \n",
            "Fit time          1.67    1.53    2.76    2.60    4.66    2.64    1.12    \n",
            "Test time         0.23    0.37    0.28    0.82    0.28    0.39    0.22    \n",
            "RMSE: 0.9379\n",
            "Evaluating RMSE, MAE of algorithm SVDpp on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9171  0.9266  0.9224  0.9120  0.9179  0.9192  0.0049  \n",
            "MAE (testset)     0.7211  0.7253  0.7234  0.7179  0.7172  0.7210  0.0031  \n",
            "Fit time          26.70   26.82   27.08   26.75   27.13   26.89   0.18    \n",
            "Test time         5.46    4.44    5.32    4.67    5.01    4.98    0.38    \n",
            "RMSE: 0.9232\n",
            "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9693  0.9677  0.9514  0.9663  0.9661  0.9642  0.0065  \n",
            "MAE (testset)     0.7620  0.7620  0.7482  0.7619  0.7612  0.7591  0.0054  \n",
            "Fit time          2.31    2.03    1.99    2.00    2.37    2.14    0.17    \n",
            "Test time         0.10    0.23    0.11    0.11    0.37    0.19    0.11    \n",
            "RMSE: 0.9657\n",
            "                SVD      SVDpp       NMF\n",
            "test_rmse  0.935832   0.919196  0.964152\n",
            "test_mae   0.738152   0.720975  0.759064\n",
            "fit_time   2.644620  26.894202  2.140512\n",
            "test_time  0.393852   4.982450  0.185665\n",
            "\n",
            "       RMSE_Check\n",
            "SVD      0.937924\n",
            "SVDpp    0.923246\n",
            "NMF      0.965669\n",
            "CPU times: user 4min 50s, sys: 2.46 s, total: 4min 53s\n",
            "Wall time: 5min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check recommendations"
      ],
      "metadata": {
        "id": "kgX97pnnaFDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def load_movie_list(filename):\n",
        "    with open(filename, encoding='ISO-8859-1') as file:\n",
        "        movies = file.readlines()\n",
        "    movie_names = [movie.strip().split(' ', 1)[1] for movie in movies]\n",
        "    return movie_names\n",
        "\n",
        "\n",
        "def make_recommendations_for_user(predictions, user_id, num_recommendations):\n",
        "    user_predictions = [pred for pred in predictions if pred.uid == str(user_id)]\n",
        "    user_predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_predictions = user_predictions[:num_recommendations]\n",
        "    recommendations = [(pred.iid, pred.est) for pred in top_predictions]\n",
        "    return recommendations\n",
        "\n",
        "def predict_movies_based_on_movie(predictions, movie_id, movie_names, num_recommendations=5):\n",
        "    movie_predictions = [pred for pred in predictions if pred.iid == str(movie_id)]\n",
        "    movie_predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "    top_predictions = movie_predictions[:num_recommendations]\n",
        "    recommendations = [(movie_names[int(pred.uid) - 1], pred.est) for pred in top_predictions]\n",
        "    return recommendations\n",
        "\n",
        "movie_ids_file = 'movie_ids.txt'\n",
        "movie_names = load_movie_list(movie_ids_file)\n",
        "\n",
        "# Make recommendations for a specific user\n",
        "user_id = 100\n",
        "num_recommendations = 7\n",
        "for name, algorithm in algorithms.items():\n",
        "  user_recommendations = make_recommendations_for_user(all_predictions[name], user_id, num_recommendations)\n",
        "  print(f\"\\nRecommendations for user {user_id} [{name}]:\")\n",
        "  for movie_id, estimated_rating in user_recommendations:\n",
        "      movie_name = movie_names[int(movie_id) - 1]\n",
        "      print(f\"Movie: {movie_name}, ID: {movie_id}, Estimated Rating: {estimated_rating:.2f}\")\n",
        "\n",
        "# Predict movies based on a specific movie\n",
        "movie_id = 316\n",
        "movie_name_ = \"As Good As It Gets (1997)\"\n",
        "# num_recommendations = 10\n",
        "for name, algorithm in algorithms.items():\n",
        "  movie_recommendations = predict_movies_based_on_movie(all_predictions[name], movie_id, movie_names, num_recommendations)\n",
        "  print(f\"\\nMovies similar to '{movie_name_}' [{name}]:\")\n",
        "  for movie_name, estimated_rating in movie_recommendations:\n",
        "      print(f\"Movie: {movie_name}, Estimated Rating: {estimated_rating:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0itdbQp0Okn",
        "outputId": "2b5de8a7-eb60-46d6-b841-8dc0daf09bfb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommendations for user 100 [SVD]:\n",
            "Movie: Titanic (1997), ID: 313, Estimated Rating: 4.37\n",
            "Movie: Good Will Hunting (1997), ID: 272, Estimated Rating: 4.16\n",
            "Movie: As Good As It Gets (1997), ID: 316, Estimated Rating: 4.01\n",
            "Movie: L.A. Confidential (1997), ID: 302, Estimated Rating: 3.72\n",
            "Movie: Game, The (1997), ID: 333, Estimated Rating: 3.71\n",
            "Movie: Apt Pupil (1998), ID: 315, Estimated Rating: 3.61\n",
            "Movie: Contact (1997), ID: 258, Estimated Rating: 3.60\n",
            "\n",
            "Recommendations for user 100 [SVDpp]:\n",
            "Movie: Good Will Hunting (1997), ID: 272, Estimated Rating: 4.29\n",
            "Movie: Titanic (1997), ID: 313, Estimated Rating: 4.13\n",
            "Movie: Contact (1997), ID: 258, Estimated Rating: 4.06\n",
            "Movie: As Good As It Gets (1997), ID: 316, Estimated Rating: 3.95\n",
            "Movie: L.A. Confidential (1997), ID: 302, Estimated Rating: 3.91\n",
            "Movie: Seven Years in Tibet (1997), ID: 690, Estimated Rating: 3.86\n",
            "Movie: Liar Liar (1997), ID: 294, Estimated Rating: 3.80\n",
            "\n",
            "Recommendations for user 100 [NMF]:\n",
            "Movie: As Good As It Gets (1997), ID: 316, Estimated Rating: 4.14\n",
            "Movie: Apt Pupil (1998), ID: 315, Estimated Rating: 4.08\n",
            "Movie: Big Bang Theory, The (1994), ID: 1235, Estimated Rating: 3.99\n",
            "Movie: Apostle, The (1997), ID: 344, Estimated Rating: 3.97\n",
            "Movie: L.A. Confidential (1997), ID: 302, Estimated Rating: 3.96\n",
            "Movie: Titanic (1997), ID: 313, Estimated Rating: 3.85\n",
            "Movie: Good Will Hunting (1997), ID: 272, Estimated Rating: 3.77\n",
            "\n",
            "Movies similar to 'As Good As It Gets (1997)' [SVD]:\n",
            "Movie: Streetcar Named Desire, A (1951), Estimated Rating: 5.00\n",
            "Movie: Kansas City (1996), Estimated Rating: 5.00\n",
            "Movie: Notorious (1946), Estimated Rating: 4.90\n",
            "Movie: So I Married an Axe Murderer (1993), Estimated Rating: 4.86\n",
            "Movie: Up Close and Personal (1996), Estimated Rating: 4.83\n",
            "Movie: Speechless (1994), Estimated Rating: 4.82\n",
            "Movie: Naked Gun 33 1/3: The Final Insult (1994), Estimated Rating: 4.81\n",
            "\n",
            "Movies similar to 'As Good As It Gets (1997)' [SVDpp]:\n",
            "Movie: Harold and Maude (1971), Estimated Rating: 5.00\n",
            "Movie: Streetcar Named Desire, A (1951), Estimated Rating: 5.00\n",
            "Movie: Naked Gun 33 1/3: The Final Insult (1994), Estimated Rating: 4.88\n",
            "Movie: Kama Sutra: A Tale of Love (1996), Estimated Rating: 4.81\n",
            "Movie: Up Close and Personal (1996), Estimated Rating: 4.76\n",
            "Movie: Lawnmower Man, The (1992), Estimated Rating: 4.73\n",
            "Movie: Kansas City (1996), Estimated Rating: 4.70\n",
            "\n",
            "Movies similar to 'As Good As It Gets (1997)' [NMF]:\n",
            "Movie: Naked Gun 33 1/3: The Final Insult (1994), Estimated Rating: 5.00\n",
            "Movie: Harold and Maude (1971), Estimated Rating: 5.00\n",
            "Movie: Streetcar Named Desire, A (1951), Estimated Rating: 5.00\n",
            "Movie: So I Married an Axe Murderer (1993), Estimated Rating: 4.97\n",
            "Movie: Old Yeller (1957), Estimated Rating: 4.93\n",
            "Movie: Wonderful, Horrible Life of Leni Riefenstahl, The (1993), Estimated Rating: 4.86\n",
            "Movie: Kama Sutra: A Tale of Love (1996), Estimated Rating: 4.82\n",
            "CPU times: user 145 ms, sys: 7.97 ms, total: 153 ms\n",
            "Wall time: 153 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of Recommendation System Results\n",
        "\n",
        "This analysis evaluated three recommendation system algorithms (SVD, SVD++, NMF) using the scikit-surprise library.\n",
        "\n",
        "\n",
        "- SVD++ achieved the lowest RMSE and MAE, suggesting potentially better prediction accuracy. However, its training time is significantly higher compared to SVD and NMF.\n",
        "- NMF had the highest RMSE and MAE, potentially indicating lower prediction accuracy.\n",
        "- SVD offers a good balance between performance (decent RMSE and MAE) and training efficiency (fastest training time).\n",
        "\n",
        "### Recommendations for Further Action\n",
        "\n",
        "* **Additional User Testing:** While the metrics provide insights into algorithm performance, user testing is crucial, real users can check which recommendations they find most relevant and helpful.\n",
        "\n",
        "* **Consider Application Needs:** If recommendation speed is a priority, SVD might be a good choice. If accuracy is critical and training time is less of a concern, SVD++ could be a potential candidate.\n",
        "\n",
        "* **Explore Other Algorithms:** The scikit-surprise library offers other algorithms like ALS (Alternating Least Squares) and FunkSVD. Consider testing these to see if they outperform the evaluated ones in specific use cases.\n"
      ],
      "metadata": {
        "id": "XDL_5t6aE1WH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Recomendation system from scratch"
      ],
      "metadata": {
        "id": "I5HroorfeHlA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and functions"
      ],
      "metadata": {
        "id": "yfRZGL2SmH1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# def load_movie_list(filename):\n",
        "#     with open(filename, encoding='ISO-8859-1') as file:\n",
        "#         movies = file.readlines()\n",
        "#     movie_names = [movie.strip().split(' ', 1)[1] for movie in movies]\n",
        "#     return movie_names\n",
        "\n",
        "def normalize_ratings(Y, R):\n",
        "    Ymean = np.sum(Y, axis=1) / np.sum(R, axis=1)\n",
        "    Ymean = np.nan_to_num(Ymean)  # Ensure no NaNs in Ymean\n",
        "    Ynorm = Y - Ymean[:, None] * R\n",
        "    return Ynorm, Ymean\n",
        "\n",
        "def cofi_cost_func(params, Y, R, num_users, num_movies, num_features, lambda_=0.0):\n",
        "    X = params[:num_movies * num_features].reshape(num_movies, num_features)\n",
        "    Theta = params[num_movies * num_features:].reshape(num_users, num_features)\n",
        "\n",
        "    J = (1 / 2) * np.sum((np.dot(X, Theta.T) * R - Y) ** 2)\n",
        "    J += (lambda_ / 2) * (np.sum(Theta ** 2) + np.sum(X ** 2))\n",
        "\n",
        "    X_grad = ((np.dot(X, Theta.T) * R - Y) @ Theta) + lambda_ * X\n",
        "    Theta_grad = ((np.dot(X, Theta.T) * R - Y).T @ X) + lambda_ * Theta\n",
        "\n",
        "    grad = np.concatenate([X_grad.ravel(), Theta_grad.ravel()])\n",
        "    return J, grad\n",
        "\n",
        "def gradient_descent(Y, R, num_users, num_movies, num_features, alpha=0.002, lambda_=0.02, iterations=1000):\n",
        "    X = np.random.rand(num_movies, num_features)\n",
        "    Theta = np.random.rand(num_users, num_features)\n",
        "    params = np.concatenate([X.ravel(), Theta.ravel()])\n",
        "\n",
        "    print('Gradient descent calculations:')\n",
        "    for i in range(iterations):\n",
        "        cost, grad = cofi_cost_func(params, Y, R, num_users, num_movies, num_features, lambda_)\n",
        "        params -= alpha * grad\n",
        "        if i % 100 == 0:\n",
        "            print(f'Iteration {i}: cost = {cost}')\n",
        "\n",
        "    X = params[:num_movies * num_features].reshape(num_movies, num_features)\n",
        "    Theta = params[num_movies * num_features:].reshape(num_users, num_features)\n",
        "\n",
        "    return X, Theta\n",
        "\n",
        "def predict_ratings(X, Theta, Ymean):\n",
        "    predictions = np.dot(X, Theta.T) + Ymean[:, None]\n",
        "    # print(f\"Predictions before clipping:\\n{predictions}\")\n",
        "    return np.clip(predictions, 1, 5)\n",
        "\n",
        "\n",
        "def make_recommendations(predicted_ratings, movie_names, user_id, num_recommendations):\n",
        "    user_row = predicted_ratings[:, user_id - 1]\n",
        "    sorted_indices = np.argsort(user_row)[::-1]\n",
        "    top_indices = sorted_indices[:num_recommendations]\n",
        "    recommendations = [(idx + 1, movie_names[idx], user_row[idx]) for idx in top_indices]\n",
        "    return recommendations\n",
        "\n",
        "def predict_movies(movie_name, movie_names, Y, R, num_recommendations=5):\n",
        "    movie_index = movie_names.index(movie_name)\n",
        "    movie_user_ratings = Y[movie_index]\n",
        "    moviematrix = pd.DataFrame(Y, index=movie_names)\n",
        "    similar_to_movie = moviematrix.T.corrwith(moviematrix.loc[movie_name])\n",
        "    corr_movie = pd.DataFrame(similar_to_movie, columns=['correlation'])\n",
        "    corr_movie.dropna(inplace=True)\n",
        "    ratings_count = R.sum(axis=1)\n",
        "    corr_movie['number of ratings'] = ratings_count\n",
        "    predictions = corr_movie[corr_movie['number of ratings'] > 100].sort_values('correlation', ascending=False)\n",
        "    return predictions.head(num_recommendations)\n",
        "\n",
        "def calculate_rmse(Y, R, predicted_ratings):\n",
        "    # Flatten arrays and filter only rated movies\n",
        "    y_true = Y[R == 1]\n",
        "    y_pred = predicted_ratings[R == 1]\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def calculate_mae(Y, R, predicted_ratings):\n",
        "    # Flatten arrays and filter only rated movies\n",
        "    y_true = Y[R == 1]\n",
        "    y_pred = predicted_ratings[R == 1]\n",
        "    return mean_absolute_error(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "i6C-LsIsgWZQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "vTEMkCh2N-ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Load data\n",
        "movie_ids_file = 'movie_ids.txt'\n",
        "movie_names = load_movie_list(movie_ids_file)\n",
        "movies_file = 'movies.mat'\n",
        "data = loadmat(movies_file)\n",
        "Y, R = data['Y'], data['R']\n",
        "\n",
        "# Normalize ratings\n",
        "Ynorm, Ymean = normalize_ratings(Y, R)\n",
        "\n",
        "# Matrix Factorization\n",
        "num_users, num_movies = Y.shape[1], Y.shape[0]\n",
        "num_features = 10  # Number of latent features\n",
        "X, Theta = gradient_descent(Ynorm, R, num_users, num_movies, num_features)\n",
        "\n",
        "# Predict ratings\n",
        "predicted_ratings = predict_ratings(X, Theta, Ymean)\n",
        "predicted_ratings = np.clip(predicted_ratings, 1, 5)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = calculate_rmse(Y, R, predicted_ratings)\n",
        "print(f\"RMSE of the predicted ratings: {rmse}\")\n",
        "\n",
        "# Calculate MAE\n",
        "mae = calculate_mae(Y, R, predicted_ratings)\n",
        "print(f\"MAE of the predicted ratings: {mae}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OSdezoBOCTG",
        "outputId": "f5729055-6f1c-4243-d1f4-3b0043c4d1d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient descent calculations:\n",
            "Iteration 0: cost = 384220.4950939644\n",
            "Iteration 100: cost = 30797.048345566127\n",
            "Iteration 200: cost = 26936.25409685916\n",
            "Iteration 300: cost = 25699.100499262022\n",
            "Iteration 400: cost = 25078.00398556196\n",
            "Iteration 500: cost = 24694.504631939253\n",
            "Iteration 600: cost = 24435.451575076007\n",
            "Iteration 700: cost = 24249.819101422163\n",
            "Iteration 800: cost = 24109.60244047785\n",
            "Iteration 900: cost = 23998.811863666397\n",
            "RMSE of the predicted ratings: 0.6876052363190657\n",
            "MAE of the predicted ratings: 0.528797810570718\n",
            "CPU times: user 1min 21s, sys: 40.6 s, total: 2min 2s\n",
            "Wall time: 1min 11s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check recommendations"
      ],
      "metadata": {
        "id": "x6E5I2BUak_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 100\n",
        "num_recommendations = 7\n",
        "recommendations = make_recommendations(predicted_ratings, movie_names, user_id, num_recommendations)\n",
        "\n",
        "# Display recommendations\n",
        "print(f\"\\nRecommendations for user with id={user_id}:\")\n",
        "for position, movie_name, rating in recommendations:\n",
        "    print(f\"ID {position}: {movie_name}, Predicted Rating: {rating:.2f}\")\n",
        "\n",
        "# General movie recommendations based on a specific movie\n",
        "movie_name_input = \"As Good As It Gets (1997)\"\n",
        "movie_recommendations = predict_movies(movie_name_input, movie_names, Y, R, num_recommendations+1)\n",
        "print(f\"\\nRecommendations based on the movie '{movie_name_input}':\")\n",
        "for idx, row in movie_recommendations.iloc[1:].iterrows():\n",
        "    print(f\"Movie: {idx}, Correlation: {row['correlation']:.2f}, Number of ratings: {row['number of ratings']:.0f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgusrV9z24zQ",
        "outputId": "f17742e9-1d35-4e39-9c34-b028c92265a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommendations for user with id=100:\n",
            "ID 1315: Inventing the Abbotts (1997), Predicted Rating: 4.89\n",
            "ID 1450: Golden Earrings (1947), Predicted Rating: 4.86\n",
            "ID 721: Mallrats (1995), Predicted Rating: 4.77\n",
            "ID 1209: Mixed Nuts (1994), Predicted Rating: 4.73\n",
            "ID 1293: Star Kid (1997), Predicted Rating: 4.65\n",
            "ID 61: Three Colors: White (1994), Predicted Rating: 4.61\n",
            "ID 538: Anastasia (1997), Predicted Rating: 4.54\n",
            "\n",
            "Recommendations based on the movie 'As Good As It Gets (1997)':\n",
            "Movie: Apt Pupil (1998), Correlation: 0.59, Number of ratings: 160\n",
            "Movie: Good Will Hunting (1997), Correlation: 0.50, Number of ratings: 198\n",
            "Movie: Wag the Dog (1997), Correlation: 0.42, Number of ratings: 137\n",
            "Movie: Titanic (1997), Correlation: 0.34, Number of ratings: 350\n",
            "Movie: Tomorrow Never Dies (1997), Correlation: 0.32, Number of ratings: 180\n",
            "Movie: Amistad (1997), Correlation: 0.30, Number of ratings: 124\n",
            "Movie: L.A. Confidential (1997), Correlation: 0.29, Number of ratings: 297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary for custom recommendation system:\n",
        "*  The custom recommendation system works!\n",
        "\n",
        "*  The custom recommendation system demonstrates a significantly lower RMSE and MAE compared to the Scikit-learn algorithms (SVD, SVDpp, and NMF), indicating a higher prediction accuracy.\n",
        "\n",
        "* Trained faster (around 2 minutes) compared to scikit-learn's SVD++ (around 5 minutes). However, the custom system takes more time due to the iterative gradient descent process compared to other algirithms.\n",
        "\n",
        "* The recommendations from the custom system also vary from those generated by the Scikit-learn algorithms, reflecting different underlying methods of user-item rating prediction.\n",
        "\n",
        "* Calulated Estimated Rating in the custom recommendation system higher than in the scikit-learn\n",
        "\n",
        "### Comparison Summary\n",
        "The comparison between the two recommendation systems reveals the following:\n",
        "\n",
        "1. **Overlap in Recommendations**:\n",
        "   - Both systems recommend **Titanic (1997)** and **Good Will Hunting (1997)** for user 100.\n",
        "   - The custom system includes unique movies such as \"Inventing the Abbotts (1997)\", \"Golden Earrings (1947)\", and \"Mallrats (1995)\" that are not found in the Surprise-based system's recommendations.\n",
        "\n",
        "2. **Movies Similar to 'As Good As It Gets (1997)'**:\n",
        "   - Common movies suggested across both systems include **Apt Pupil (1998)** and **Good Will Hunting (1997)**.\n",
        "   - The Surprise-based system suggests classic and highly-rated older movies like **Streetcar Named Desire, A (1951)** and **Notorious (1946)**, while the custom system focuses more on correlation-based recommendations from the same era as \"As Good As It Gets (1997)\".\n",
        "\n",
        "In summary, while there are overlaps in some recommendations, particularly for popular movies like \"Titanic\" and \"Good Will Hunting\", the custom recommendation system provides a unique set of movie suggestions for user 100, especially emphasizing movies that are less mainstream. Similarly, the recommendations based on similarity to \"As Good As It Gets (1997)\" highlight different methodologies: the Surprise-based system focuses on highly-rated classics, while the custom system suggests movies with strong correlation based on user ratings."
      ],
      "metadata": {
        "id": "Ow-ExGysL5hE"
      }
    }
  ]
}